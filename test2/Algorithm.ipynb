{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Thuật toán sử dung: neural network đơn giản chỉ gồm một lớp softmax, lý do sử dụng:\n",
    "    - Tập dữ liệu đối với tập train bị mất cân bằng có những nhãn rất ít mẫu, do đó một mô hình mạng phức tạp rất dễ gây overfit.\n",
    "    - Đây là bài toán phân loại với nhiều nhãn, ta không cần quan tâm quá nhiều đến vị trí từ trong các câu do đó việc sử dụng các thuật toán hay sử dụng cho chuỗi như LSTM là không cần thiết.Ta cần vector hóa các mãu đào tạo cộng với việc ta cần quan tâm là làm sao để có được keyword phân biệt giữa các nhãn => sử dụng tfidf là phù hợp.\n",
    "    - Neural network là một thuật toán rất dễ fit với dữ liệu đào tạo. Do đặc thù của thuật toán vector hóa mà mỗi mẫu sau khi vector hóa sẽ có rất nhiều phần tử 0 (những từ không có trong mẫu), những input nào bằng 0 thì weight sẽ hầu như không được cập nhật đồng nghĩa với việc những từ nào mà trong mẫu có sẽ được cập nhật weight tại đó.\n",
    "    - Sau khi vector hóa các mẫu, tập dữ liệu sẽ có chiều rất lớn, do đó nếu sử một số thuật toán thường gặp như KNN hay SVM sẽ không phù hợp, đối với KNN thì chỉ hiệu quả với tập dữ liệu chiều thấp và đối với dữ liệu chiều cao như trong bài toán KNN sẽ phải tính toán một lượng rất lớn, đối với SVM việc tính toán với dữ liệu chiều cao sẽ rất lâu. Một thuật toán hay sử dụng khác là Random forest đối với dữ liệu imbalance, nhưng qua thử nghiệm hiện tại thuật toán này cho kết quả chưa tốt bằng so với sử dụng neural network.\n",
    "- Kết quả: \n",
    "    - Accuracy đối với tập test khoảng 0.916 và train là 0.986. Kết quả này đang bị overfit nhưng đã hạn chế hơn rất nhiều so với khi sử dụng các thuật toán khác.\n",
    "    - Việc sử dụng k fold hiện tại chưa cải thiện được kết quả.\n",
    "- Một số phương pháp có thể thử nghiệm để cải thiện model:\n",
    "    - Sử dụng word embedding.\n",
    "    - Tăng thêm lượng dữ liệu đối với các nhãn có kết quả thấp.\n",
    "    - Sử dụng thêm nhiều thuật toán khác, nếu các thuật toán này có kết quả tốt hơn hoặc bằng kết quả hiện tại thì có thể dùng voting hoặc một cách khác là sử dụng Ensemble model.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.models import Model\n",
    "import re\n",
    "from pyvi import ViTokenizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.utils import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(txt):\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub('[\\d\\'\\\\\\.\\,\\#\\$\\%\\^\\&\\*\\(\\)\\!\\+\\-\\_\\\"\\:\\?\\<\\>\\{\\}\\[\\];\\(\\)]','',txt)\n",
    "    txt = re.sub('(\\\\r\\\\n)|[\\/]',' ',txt)\n",
    "    txt = re.sub('[^zxcvbnmasdfghjklqwertyuiop\\sàáảãạâầấẩẫậăằắẳẵặèéẻẽẹêềếểễệđìíỉĩịòóỏõọôồốổỗộơờớởỡợùúủũụưừứửữựỳýỷỹỵÀÁẢÃẠÂẦẤẨẪẬĂẰẮẲẴẶÈÉẺẼẸÊỀẾỂỄỆĐÌÍỈĨỊÒÓỎÕỌÔỒỐỔỖỘƠỜỚỞỠỢÙÚỦŨỤƯỪỨỬỮỰỲÝỶỸỴÂĂĐÔƠƯ]','',txt)\n",
    "    \n",
    "    return txt\n",
    "\n",
    "def word_separation(txt):\n",
    "    return ViTokenizer.tokenize(txt)\n",
    "\n",
    "def pad(tokenizer, sequences, max_length, trunc_type):\n",
    "    sequences = tokenizer.texts_to_sequences(sequences)\n",
    "    padded = pad_sequences(sequences, maxlen = max_length, truncating = trunc_type)\n",
    "    return padded\n",
    "\n",
    "def remove_stop_word(txt):\n",
    "    stop_words = ['của', 'và', 'có', 'là', 'một', 'trong', 'không', 'các', 'được', 'cho', 'với', 'những', 'người', 'đã', 'tôi', 'khi', 'này', 'ở', 'để', 'sẽ', 'công', 'cũng', 'học', 'thể', 'như', 'vào', 'đến', 'ra', 'làm', 'về', 'phải', 'nhiều', 'từ', 'đó', 'đầu', 'anh', 'năm', 'nhưng', 'tại', 'lại', 'chỉ', 'nhà', 'thành', 'sự', 'trên', 'sau', 'số', 'còn', 'hiện', 'gia']\n",
    "    words = []\n",
    "    for word in txt.strip().split():\n",
    "        if word not in stop_words:\n",
    "            words.append(word)\n",
    "    return ' '.join(words)\n",
    "\n",
    "def read_data(path_foder):\n",
    "    data = {}\n",
    "    content = []\n",
    "    label = []\n",
    "    typee = []\n",
    "    for path in path_foder:\n",
    "        for direc_name in os.listdir(path):\n",
    "            for file_name in os.listdir(path + '/' + direc_name):\n",
    "                with open(path + '/' + direc_name + '/' + file_name,'rb') as f:\n",
    "                    file = f.read()\n",
    "                    file = file.decode(\"utf-16\").strip()\n",
    "                    content.append(file)\n",
    "                    label.append(direc_name)\n",
    "                    typee.append(path)\n",
    "\n",
    "    data['content'] = content\n",
    "    data['label'] = label\n",
    "    data['type'] = typee\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(27, activation = 'softmax', input_dim=X_train.shape[1], kernel_regularizer = regularizers.l2(0.00001)))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "path_foder = ['train', 'test']\n",
    "df = read_data(path_foder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Loại bỏ các kí tự không cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loại bỏ các kí tự không cần thiết\n",
    "df[\"new_content\"] = df.content.apply(text_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Tách từ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tách từ\n",
    "df[\"word_separation\"] = df.new_content.apply(word_separation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Đếm số lượng từ mỗi mẫu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# đếm số lượng từ ở mỗi sample\n",
    "df[\"number_word\"] = df.word_separation.apply(lambda txt: len(txt.split(' ')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Tìm Stop word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.where(df.type == 'train').dropna()\n",
    "vocab_size = 50000\n",
    "tokenizer = Tokenizer(num_words = vocab_size, filters='')\n",
    "tokenizer.fit_on_texts(df_train.new_content)\n",
    "word_index = tokenizer.word_index\n",
    "stop_words = list(word_index)[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Loại bỏ Stop word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>type</th>\n",
       "      <th>new_content</th>\n",
       "      <th>word_separation</th>\n",
       "      <th>number_word</th>\n",
       "      <th>remove_stop_word</th>\n",
       "      <th>number_word_remove_stop_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Đó là chủ đề liveshow Sắc màu âm nhạc tháng 4,...</td>\n",
       "      <td>Am nhac</td>\n",
       "      <td>train</td>\n",
       "      <td>đó là chủ đề liveshow sắc màu âm nhạc tháng  s...</td>\n",
       "      <td>đó là chủ_đề liveshow sắc_màu âm_nhạc tháng sẽ...</td>\n",
       "      <td>73</td>\n",
       "      <td>chủ_đề liveshow sắc_màu âm_nhạc tháng diễn lúc...</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Giống như Keiko Matsui, Blackmore's Night được...</td>\n",
       "      <td>Am nhac</td>\n",
       "      <td>train</td>\n",
       "      <td>giống như keiko matsui blackmores night được h...</td>\n",
       "      <td>giống như keiko matsui blackmores night được h...</td>\n",
       "      <td>694</td>\n",
       "      <td>giống keiko matsui blackmores night hầu_hết bá...</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vừa trở về Việt Nam sau chuyến lưu diễn 3 tuần...</td>\n",
       "      <td>Am nhac</td>\n",
       "      <td>train</td>\n",
       "      <td>vừa trở về việt nam sau chuyến lưu diễn  tuần ...</td>\n",
       "      <td>vừa trở về việt nam sau chuyến lưu_diễn tuần t...</td>\n",
       "      <td>346</td>\n",
       "      <td>vừa trở việt nam chuyến lưu_diễn tuần mỹ ca_sĩ...</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chương trình ca nhạc mừng sinh nhật lần thứ 20...</td>\n",
       "      <td>Am nhac</td>\n",
       "      <td>train</td>\n",
       "      <td>chương trình ca nhạc mừng sinh nhật lần thứ  c...</td>\n",
       "      <td>chương_trình ca_nhạc mừng sinh_nhật lần thứ củ...</td>\n",
       "      <td>118</td>\n",
       "      <td>chương_trình ca_nhạc mừng sinh_nhật lần thứ đo...</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Ta là một khách mày râu/Đứng đi lạng chạng dư...</td>\n",
       "      <td>Am nhac</td>\n",
       "      <td>train</td>\n",
       "      <td>ta là một khách mày râu đứng đi lạng chạng dướ...</td>\n",
       "      <td>ta là một khách mày râu đứng đi lạng chạng dướ...</td>\n",
       "      <td>476</td>\n",
       "      <td>ta khách mày râu đứng đi lạng chạng dưới bầu_t...</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26446</th>\n",
       "      <td>Trương Thanh Long: 'Bạn bè bảo tôi là bon chen...</td>\n",
       "      <td>Thoi trang</td>\n",
       "      <td>test</td>\n",
       "      <td>trương thanh long bạn bè bảo tôi là bon chen s...</td>\n",
       "      <td>trương thanh_long bạn_bè bảo tôi là bon_chen s...</td>\n",
       "      <td>551</td>\n",
       "      <td>trương thanh_long bạn_bè bảo bon_chen đoạt giả...</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26447</th>\n",
       "      <td>Người đẹp dễ dụ bằng tiền\\r\\nKhông phải ngẫu n...</td>\n",
       "      <td>Thoi trang</td>\n",
       "      <td>test</td>\n",
       "      <td>người đẹp dễ dụ bằng tiền không phải ngẫu nhiê...</td>\n",
       "      <td>người đẹp dễ dụ bằng tiền không phải ngẫu_nhiê...</td>\n",
       "      <td>1036</td>\n",
       "      <td>đẹp dễ dụ bằng tiền ngẫu_nhiên mà đa_số đẹp đă...</td>\n",
       "      <td>671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26448</th>\n",
       "      <td>21 người đẹp vào vòng chung kết Hoa hậu toàn q...</td>\n",
       "      <td>Thoi trang</td>\n",
       "      <td>test</td>\n",
       "      <td>người đẹp vào vòng chung kết hoa hậu toàn quố...</td>\n",
       "      <td>người đẹp vào vòng chung_kết hoa_hậu toàn_quốc...</td>\n",
       "      <td>220</td>\n",
       "      <td>đẹp vòng chung_kết hoa_hậu toàn_quốc đêm khai_...</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26449</th>\n",
       "      <td>'Hoa hậu phải rành ngoại ngữ'\\r\\nNữ hoàng sắc ...</td>\n",
       "      <td>Thoi trang</td>\n",
       "      <td>test</td>\n",
       "      <td>hoa hậu phải rành ngoại ngữ nữ hoàng sắc đẹp v...</td>\n",
       "      <td>hoa_hậu phải rành ngoại_ngữ nữ_hoàng sắc_đẹp v...</td>\n",
       "      <td>358</td>\n",
       "      <td>hoa_hậu rành ngoại_ngữ nữ_hoàng sắc_đẹp việt n...</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26450</th>\n",
       "      <td>Áo dài Ngân An sang Thuỵ Điển\\r\\nBộ sưu tập \"H...</td>\n",
       "      <td>Thoi trang</td>\n",
       "      <td>test</td>\n",
       "      <td>áo dài ngân an sang thuỵ điển bộ sưu tập hà nộ...</td>\n",
       "      <td>áo_dài ngân an sang thuỵ điển bộ sưu_tập hà nộ...</td>\n",
       "      <td>296</td>\n",
       "      <td>áo_dài ngân an sang thuỵ điển bộ sưu_tập hà nộ...</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26451 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content       label   type  \\\n",
       "0      Đó là chủ đề liveshow Sắc màu âm nhạc tháng 4,...     Am nhac  train   \n",
       "1      Giống như Keiko Matsui, Blackmore's Night được...     Am nhac  train   \n",
       "2      Vừa trở về Việt Nam sau chuyến lưu diễn 3 tuần...     Am nhac  train   \n",
       "3      Chương trình ca nhạc mừng sinh nhật lần thứ 20...     Am nhac  train   \n",
       "4      \"Ta là một khách mày râu/Đứng đi lạng chạng dư...     Am nhac  train   \n",
       "...                                                  ...         ...    ...   \n",
       "26446  Trương Thanh Long: 'Bạn bè bảo tôi là bon chen...  Thoi trang   test   \n",
       "26447  Người đẹp dễ dụ bằng tiền\\r\\nKhông phải ngẫu n...  Thoi trang   test   \n",
       "26448  21 người đẹp vào vòng chung kết Hoa hậu toàn q...  Thoi trang   test   \n",
       "26449  'Hoa hậu phải rành ngoại ngữ'\\r\\nNữ hoàng sắc ...  Thoi trang   test   \n",
       "26450  Áo dài Ngân An sang Thuỵ Điển\\r\\nBộ sưu tập \"H...  Thoi trang   test   \n",
       "\n",
       "                                             new_content  \\\n",
       "0      đó là chủ đề liveshow sắc màu âm nhạc tháng  s...   \n",
       "1      giống như keiko matsui blackmores night được h...   \n",
       "2      vừa trở về việt nam sau chuyến lưu diễn  tuần ...   \n",
       "3      chương trình ca nhạc mừng sinh nhật lần thứ  c...   \n",
       "4      ta là một khách mày râu đứng đi lạng chạng dướ...   \n",
       "...                                                  ...   \n",
       "26446  trương thanh long bạn bè bảo tôi là bon chen s...   \n",
       "26447  người đẹp dễ dụ bằng tiền không phải ngẫu nhiê...   \n",
       "26448   người đẹp vào vòng chung kết hoa hậu toàn quố...   \n",
       "26449  hoa hậu phải rành ngoại ngữ nữ hoàng sắc đẹp v...   \n",
       "26450  áo dài ngân an sang thuỵ điển bộ sưu tập hà nộ...   \n",
       "\n",
       "                                         word_separation  number_word  \\\n",
       "0      đó là chủ_đề liveshow sắc_màu âm_nhạc tháng sẽ...           73   \n",
       "1      giống như keiko matsui blackmores night được h...          694   \n",
       "2      vừa trở về việt nam sau chuyến lưu_diễn tuần t...          346   \n",
       "3      chương_trình ca_nhạc mừng sinh_nhật lần thứ củ...          118   \n",
       "4      ta là một khách mày râu đứng đi lạng chạng dướ...          476   \n",
       "...                                                  ...          ...   \n",
       "26446  trương thanh_long bạn_bè bảo tôi là bon_chen s...          551   \n",
       "26447  người đẹp dễ dụ bằng tiền không phải ngẫu_nhiê...         1036   \n",
       "26448  người đẹp vào vòng chung_kết hoa_hậu toàn_quốc...          220   \n",
       "26449  hoa_hậu phải rành ngoại_ngữ nữ_hoàng sắc_đẹp v...          358   \n",
       "26450  áo_dài ngân an sang thuỵ điển bộ sưu_tập hà nộ...          296   \n",
       "\n",
       "                                        remove_stop_word  \\\n",
       "0      chủ_đề liveshow sắc_màu âm_nhạc tháng diễn lúc...   \n",
       "1      giống keiko matsui blackmores night hầu_hết bá...   \n",
       "2      vừa trở việt nam chuyến lưu_diễn tuần mỹ ca_sĩ...   \n",
       "3      chương_trình ca_nhạc mừng sinh_nhật lần thứ đo...   \n",
       "4      ta khách mày râu đứng đi lạng chạng dưới bầu_t...   \n",
       "...                                                  ...   \n",
       "26446  trương thanh_long bạn_bè bảo bon_chen đoạt giả...   \n",
       "26447  đẹp dễ dụ bằng tiền ngẫu_nhiên mà đa_số đẹp đă...   \n",
       "26448  đẹp vòng chung_kết hoa_hậu toàn_quốc đêm khai_...   \n",
       "26449  hoa_hậu rành ngoại_ngữ nữ_hoàng sắc_đẹp việt n...   \n",
       "26450  áo_dài ngân an sang thuỵ điển bộ sưu_tập hà nộ...   \n",
       "\n",
       "       number_word_remove_stop_word  \n",
       "0                                54  \n",
       "1                               506  \n",
       "2                               229  \n",
       "3                               108  \n",
       "4                               304  \n",
       "...                             ...  \n",
       "26446                           357  \n",
       "26447                           671  \n",
       "26448                           146  \n",
       "26449                           250  \n",
       "26450                           209  \n",
       "\n",
       "[26451 rows x 8 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"remove_stop_word\"] = df.word_separation.apply(remove_stop_word)\n",
    "df[\"number_word_remove_stop_word\"] = df.remove_stop_word.apply(lambda txt: len(txt.split(' ')))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data.csv', encoding='utf-16')\n",
    "df_train = df.where(df.type == 'train').dropna()\n",
    "df_test = df.where(df.type == 'test').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train[\"number_word\"].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "number_per_label = df_train.label.value_counts()\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(9,9)\n",
    "ax.barh(y=number_per_label.index, width=number_per_label.values);\n",
    "ax.set_title('Số lượng mẫu mỗi nhãn tập train');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfIdfVectorizer = TfidfVectorizer(encoding = 'utf-16',min_df=5, use_idf=True)\n",
    "tfIdf = tfIdfVectorizer.fit(df_train.remove_stop_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2  X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train  = tfIdf.transform(df_train.remove_stop_word).toarray()\n",
    "X_test  = tfIdf.transform(df_test.remove_stop_word).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelEncoder().fit(df_train.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train  = lb.transform(df_train.label.values)\n",
    "y_test = lb.transform(df_test.label.values)\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "X_test, y_test = shuffle(X_test, y_test, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3.1 neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'model_checkpoints'\n",
    "checkpoint = ModelCheckpoint(\n",
    "                filepath = checkpoint_path,\n",
    "                save_weights_only = False,\n",
    "                monitor = 'val_accuracy',\n",
    "                mode = 'max',\n",
    "                save_best_only=True,\n",
    "                verbose=1\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "450/450 [==============================] - 4s 9ms/step - loss: 2.9332 - accuracy: 0.4812 - val_loss: 2.2226 - val_accuracy: 0.6578\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.65775, saving model to model_checkpoints\n",
      "INFO:tensorflow:Assets written to: model_checkpoints\\assets\n",
      "Epoch 2/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 1.9321 - accuracy: 0.7483 - val_loss: 1.7141 - val_accuracy: 0.7556\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.65775 to 0.75563, saving model to model_checkpoints\n",
      "INFO:tensorflow:Assets written to: model_checkpoints\\assets\n",
      "Epoch 3/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 1.4582 - accuracy: 0.8292 - val_loss: 1.4254 - val_accuracy: 0.8085\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.75563 to 0.80846, saving model to model_checkpoints\n",
      "INFO:tensorflow:Assets written to: model_checkpoints\\assets\n",
      "Epoch 4/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 1.1831 - accuracy: 0.8821 - val_loss: 1.2470 - val_accuracy: 0.8451\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.80846 to 0.84506, saving model to model_checkpoints\n",
      "INFO:tensorflow:Assets written to: model_checkpoints\\assets\n",
      "Epoch 5/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 1.0032 - accuracy: 0.9161 - val_loss: 1.1266 - val_accuracy: 0.8670\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.84506 to 0.86701, saving model to model_checkpoints\n",
      "INFO:tensorflow:Assets written to: model_checkpoints\\assets\n",
      "Epoch 6/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.8985 - accuracy: 0.9310 - val_loss: 1.0404 - val_accuracy: 0.8805\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.86701 to 0.88051, saving model to model_checkpoints\n",
      "INFO:tensorflow:Assets written to: model_checkpoints\\assets\n",
      "Epoch 7/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.8270 - accuracy: 0.9405 - val_loss: 0.9765 - val_accuracy: 0.8883\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.88051 to 0.88829, saving model to model_checkpoints\n",
      "INFO:tensorflow:Assets written to: model_checkpoints\\assets\n",
      "Epoch 8/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.7520 - accuracy: 0.9515 - val_loss: 0.9260 - val_accuracy: 0.8942\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.88829 to 0.89417, saving model to model_checkpoints\n",
      "INFO:tensorflow:Assets written to: model_checkpoints\\assets\n",
      "Epoch 9/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.7100 - accuracy: 0.9519 - val_loss: 0.8856 - val_accuracy: 0.9001\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.89417 to 0.90013, saving model to model_checkpoints\n",
      "INFO:tensorflow:Assets written to: model_checkpoints\\assets\n",
      "Epoch 10/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.6582 - accuracy: 0.9588 - val_loss: 0.8524 - val_accuracy: 0.9028\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.90013 to 0.90278, saving model to model_checkpoints\n",
      "INFO:tensorflow:Assets written to: model_checkpoints\\assets\n",
      "Epoch 11/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.6328 - accuracy: 0.9628 - val_loss: 0.8243 - val_accuracy: 0.9041\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.90278 to 0.90411, saving model to model_checkpoints\n",
      "INFO:tensorflow:Assets written to: model_checkpoints\\assets\n",
      "Epoch 12/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.6063 - accuracy: 0.9632 - val_loss: 0.7999 - val_accuracy: 0.9067\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.90411 to 0.90667, saving model to model_checkpoints\n",
      "INFO:tensorflow:Assets written to: model_checkpoints\\assets\n",
      "Epoch 13/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.5862 - accuracy: 0.9654 - val_loss: 0.7794 - val_accuracy: 0.9075\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.90667 to 0.90750, saving model to model_checkpoints\n",
      "INFO:tensorflow:Assets written to: model_checkpoints\\assets\n",
      "Epoch 14/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.5612 - accuracy: 0.9698 - val_loss: 0.7613 - val_accuracy: 0.9089\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.90750 to 0.90891, saving model to model_checkpoints\n",
      "INFO:tensorflow:Assets written to: model_checkpoints\\assets\n",
      "Epoch 15/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.5434 - accuracy: 0.9683 - val_loss: 0.7460 - val_accuracy: 0.9094\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.90891 to 0.90941, saving model to model_checkpoints\n",
      "INFO:tensorflow:Assets written to: model_checkpoints\\assets\n",
      "Epoch 16/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.5352 - accuracy: 0.9697 - val_loss: 0.7316 - val_accuracy: 0.9108\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.90941 to 0.91081, saving model to model_checkpoints\n",
      "INFO:tensorflow:Assets written to: model_checkpoints\\assets\n",
      "Epoch 17/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.5176 - accuracy: 0.9727 - val_loss: 0.7198 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.91081\n",
      "Epoch 18/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.5034 - accuracy: 0.9742 - val_loss: 0.7090 - val_accuracy: 0.9112\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.91081 to 0.91123, saving model to model_checkpoints\n",
      "INFO:tensorflow:Assets written to: model_checkpoints\\assets\n",
      "Epoch 19/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.4920 - accuracy: 0.9752 - val_loss: 0.6997 - val_accuracy: 0.9121\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.91123 to 0.91214, saving model to model_checkpoints\n",
      "INFO:tensorflow:Assets written to: model_checkpoints\\assets\n",
      "Epoch 20/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.4949 - accuracy: 0.9730 - val_loss: 0.6910 - val_accuracy: 0.9131\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.91214 to 0.91313, saving model to model_checkpoints\n",
      "INFO:tensorflow:Assets written to: model_checkpoints\\assets\n",
      "Epoch 21/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.4778 - accuracy: 0.9735 - val_loss: 0.6847 - val_accuracy: 0.9116\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.91313\n",
      "Epoch 22/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.4678 - accuracy: 0.9765 - val_loss: 0.6777 - val_accuracy: 0.9129\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.91313\n",
      "Epoch 23/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.4602 - accuracy: 0.9772 - val_loss: 0.6716 - val_accuracy: 0.9129\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.91313\n",
      "Epoch 24/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.4562 - accuracy: 0.9786 - val_loss: 0.6660 - val_accuracy: 0.9135\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.91313 to 0.91355, saving model to model_checkpoints\n",
      "INFO:tensorflow:Assets written to: model_checkpoints\\assets\n",
      "Epoch 25/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.4563 - accuracy: 0.9789 - val_loss: 0.6614 - val_accuracy: 0.9137\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.91355 to 0.91371, saving model to model_checkpoints\n",
      "INFO:tensorflow:Assets written to: model_checkpoints\\assets\n",
      "Epoch 26/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.4456 - accuracy: 0.9805 - val_loss: 0.6570 - val_accuracy: 0.9140\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.91371 to 0.91396, saving model to model_checkpoints\n",
      "INFO:tensorflow:Assets written to: model_checkpoints\\assets\n",
      "Epoch 27/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.4458 - accuracy: 0.9784 - val_loss: 0.6536 - val_accuracy: 0.9138\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.91396\n",
      "Epoch 28/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.4381 - accuracy: 0.9809 - val_loss: 0.6498 - val_accuracy: 0.9141\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.91396 to 0.91413, saving model to model_checkpoints\n",
      "INFO:tensorflow:Assets written to: model_checkpoints\\assets\n",
      "Epoch 29/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.4341 - accuracy: 0.9818 - val_loss: 0.6465 - val_accuracy: 0.9142\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.91413 to 0.91421, saving model to model_checkpoints\n",
      "INFO:tensorflow:Assets written to: model_checkpoints\\assets\n",
      "Epoch 30/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.4290 - accuracy: 0.9814 - val_loss: 0.6441 - val_accuracy: 0.9140\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.91421\n",
      "Epoch 31/50\n",
      "450/450 [==============================] - 3s 8ms/step - loss: 0.4247 - accuracy: 0.9815 - val_loss: 0.6410 - val_accuracy: 0.9145\n",
      "\n",
      "Epoch 00031: val_accuracy improved from 0.91421 to 0.91454, saving model to model_checkpoints\n",
      "INFO:tensorflow:Assets written to: model_checkpoints\\assets\n",
      "Epoch 32/50\n",
      "450/450 [==============================] - 3s 8ms/step - loss: 0.4243 - accuracy: 0.9818 - val_loss: 0.6387 - val_accuracy: 0.9137\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.91454\n",
      "Epoch 33/50\n",
      "450/450 [==============================] - 3s 8ms/step - loss: 0.4218 - accuracy: 0.9826 - val_loss: 0.6364 - val_accuracy: 0.9140\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.91454\n",
      "Epoch 34/50\n",
      "450/450 [==============================] - 3s 8ms/step - loss: 0.4222 - accuracy: 0.9814 - val_loss: 0.6338 - val_accuracy: 0.9146\n",
      "\n",
      "Epoch 00034: val_accuracy improved from 0.91454 to 0.91462, saving model to model_checkpoints\n",
      "INFO:tensorflow:Assets written to: model_checkpoints\\assets\n",
      "Epoch 35/50\n",
      "450/450 [==============================] - 3s 8ms/step - loss: 0.4173 - accuracy: 0.9820 - val_loss: 0.6318 - val_accuracy: 0.9148\n",
      "\n",
      "Epoch 00035: val_accuracy improved from 0.91462 to 0.91479, saving model to model_checkpoints\n",
      "INFO:tensorflow:Assets written to: model_checkpoints\\assets\n",
      "Epoch 36/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.4129 - accuracy: 0.9831 - val_loss: 0.6300 - val_accuracy: 0.9145\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.91479\n",
      "Epoch 37/50\n",
      "450/450 [==============================] - 3s 8ms/step - loss: 0.4087 - accuracy: 0.9845 - val_loss: 0.6290 - val_accuracy: 0.9140\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.91479\n",
      "Epoch 38/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.4167 - accuracy: 0.9821 - val_loss: 0.6273 - val_accuracy: 0.9144\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.91479\n",
      "Epoch 39/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.4069 - accuracy: 0.9836 - val_loss: 0.6259 - val_accuracy: 0.9145\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.91479\n",
      "Epoch 40/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.4083 - accuracy: 0.9830 - val_loss: 0.6248 - val_accuracy: 0.9145\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.91479\n",
      "Epoch 41/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.4029 - accuracy: 0.9833 - val_loss: 0.6233 - val_accuracy: 0.9153\n",
      "\n",
      "Epoch 00041: val_accuracy improved from 0.91479 to 0.91529, saving model to model_checkpoints\n",
      "INFO:tensorflow:Assets written to: model_checkpoints\\assets\n",
      "Epoch 42/50\n",
      "450/450 [==============================] - 3s 8ms/step - loss: 0.4042 - accuracy: 0.9841 - val_loss: 0.6220 - val_accuracy: 0.9157\n",
      "\n",
      "Epoch 00042: val_accuracy improved from 0.91529 to 0.91570, saving model to model_checkpoints\n",
      "INFO:tensorflow:Assets written to: model_checkpoints\\assets\n",
      "Epoch 43/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.4027 - accuracy: 0.9861 - val_loss: 0.6208 - val_accuracy: 0.9162\n",
      "\n",
      "Epoch 00043: val_accuracy improved from 0.91570 to 0.91620, saving model to model_checkpoints\n",
      "INFO:tensorflow:Assets written to: model_checkpoints\\assets\n",
      "Epoch 44/50\n",
      "450/450 [==============================] - 3s 8ms/step - loss: 0.4034 - accuracy: 0.9859 - val_loss: 0.6207 - val_accuracy: 0.9152\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.91620\n",
      "Epoch 45/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.4025 - accuracy: 0.9831 - val_loss: 0.6194 - val_accuracy: 0.9155\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.91620\n",
      "Epoch 46/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.4009 - accuracy: 0.9834 - val_loss: 0.6195 - val_accuracy: 0.9152\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.91620\n",
      "Epoch 47/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.4046 - accuracy: 0.9832 - val_loss: 0.6184 - val_accuracy: 0.9150\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.91620\n",
      "Epoch 48/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.4033 - accuracy: 0.9838 - val_loss: 0.6171 - val_accuracy: 0.9155\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.91620\n",
      "Epoch 49/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.3948 - accuracy: 0.9855 - val_loss: 0.6167 - val_accuracy: 0.9154\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.91620\n",
      "Epoch 50/50\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.4007 - accuracy: 0.9853 - val_loss: 0.6162 - val_accuracy: 0.9156\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.91620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1779be08860>"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_test, y_test), callbacks=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "             Am nhac       0.92      0.93      0.93       813\n",
      "             Am thuc       0.98      0.93      0.95       400\n",
      "        Bat dong san       0.99      0.94      0.97       282\n",
      "             Bong da       0.99      1.00      0.99      1464\n",
      "         Chung khoan       0.99      0.96      0.97       320\n",
      "              Cum ga       1.00      0.98      0.99       381\n",
      "    Cuoc song do day       0.66      0.90      0.76       405\n",
      "              Du hoc       0.98      0.92      0.95       394\n",
      "             Du lich       0.92      0.96      0.94       565\n",
      "       Duong vao WTO       0.99      0.83      0.90       191\n",
      "            Gia dinh       0.88      0.61      0.72       280\n",
      "    Giai tri tin hoc       0.78      0.92      0.85       707\n",
      "            Giao duc       0.92      0.93      0.93       707\n",
      "           Gioi tinh       0.89      0.93      0.91       268\n",
      "    Hackers va Virus       1.00      0.87      0.93       319\n",
      "             Hinh su       0.99      0.90      0.94       196\n",
      "     Khong gian song       0.98      0.91      0.95        58\n",
      "  Kinh doanh quoc te       0.88      0.93      0.91       559\n",
      "             Lam dep       0.95      0.96      0.95       735\n",
      "            Loi song       0.72      0.63      0.67       214\n",
      "             Mua sam       0.79      0.75      0.77        84\n",
      "            My thuat       0.98      0.82      0.89       144\n",
      "   San khau dien anh       0.95      0.93      0.94      1030\n",
      "San pham tin hoc moi       0.91      0.84      0.87       595\n",
      "              Tennis       1.00      0.99      0.99       283\n",
      "        The gioi tre       0.83      0.84      0.83       380\n",
      "          Thoi trang       0.86      0.90      0.88       302\n",
      "\n",
      "            accuracy                           0.92     12076\n",
      "           macro avg       0.92      0.89      0.90     12076\n",
      "        weighted avg       0.92      0.92      0.92     12076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model  = load_model(checkpoint_path)\n",
    "y_pred = best_model.predict_classes(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred, target_names= lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thoi trang']\n"
     ]
    }
   ],
   "source": [
    "test = tfIdf.transform(['áo đẹp quá']).toarray()\n",
    "pred = model.predict_classes(test)\n",
    "print(lb.classes_[pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Sử dụng K-ford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [    0     1     2 ... 14371 14373 14374] TEST: [   20    21    58 ... 14353 14367 14372]\n",
      "Epoch 1/30\n",
      "405/405 [==============================] - 4s 10ms/step - loss: 2.9655 - accuracy: 0.4983 - val_loss: 2.2079 - val_accuracy: 0.6676\n",
      "Epoch 2/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 2.0194 - accuracy: 0.7324 - val_loss: 1.6808 - val_accuracy: 0.7747\n",
      "Epoch 3/30\n",
      "405/405 [==============================] - 3s 8ms/step - loss: 1.5306 - accuracy: 0.8216 - val_loss: 1.3783 - val_accuracy: 0.8213\n",
      "Epoch 4/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 1.2444 - accuracy: 0.8773 - val_loss: 1.1918 - val_accuracy: 0.8581\n",
      "Epoch 5/30\n",
      "405/405 [==============================] - 3s 8ms/step - loss: 1.0546 - accuracy: 0.9088 - val_loss: 1.0686 - val_accuracy: 0.8762\n",
      "Epoch 6/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.9351 - accuracy: 0.9278 - val_loss: 0.9816 - val_accuracy: 0.8839\n",
      "Epoch 7/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.8487 - accuracy: 0.9439 - val_loss: 0.9175 - val_accuracy: 0.8915\n",
      "Epoch 8/30\n",
      "405/405 [==============================] - 3s 8ms/step - loss: 0.7846 - accuracy: 0.9505 - val_loss: 0.8678 - val_accuracy: 0.8971\n",
      "Epoch 9/30\n",
      "405/405 [==============================] - 3s 8ms/step - loss: 0.7410 - accuracy: 0.9514 - val_loss: 0.8283 - val_accuracy: 0.9033\n",
      "Epoch 10/30\n",
      "405/405 [==============================] - 3s 8ms/step - loss: 0.6917 - accuracy: 0.9576 - val_loss: 0.7957 - val_accuracy: 0.9075\n",
      "Epoch 11/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.6653 - accuracy: 0.9601 - val_loss: 0.7687 - val_accuracy: 0.9082\n",
      "Epoch 12/30\n",
      "405/405 [==============================] - 3s 8ms/step - loss: 0.6265 - accuracy: 0.9628 - val_loss: 0.7456 - val_accuracy: 0.9096\n",
      "Epoch 13/30\n",
      "405/405 [==============================] - 3s 8ms/step - loss: 0.6041 - accuracy: 0.9684 - val_loss: 0.7258 - val_accuracy: 0.9124\n",
      "Epoch 14/30\n",
      "405/405 [==============================] - 4s 10ms/step - loss: 0.5787 - accuracy: 0.9708 - val_loss: 0.7087 - val_accuracy: 0.9117\n",
      "Epoch 15/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.5666 - accuracy: 0.9685 - val_loss: 0.6935 - val_accuracy: 0.9138\n",
      "Epoch 16/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.5488 - accuracy: 0.9710 - val_loss: 0.6802 - val_accuracy: 0.9145\n",
      "Epoch 17/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.5370 - accuracy: 0.9716 - val_loss: 0.6687 - val_accuracy: 0.9138\n",
      "Epoch 18/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.5186 - accuracy: 0.9741 - val_loss: 0.6584 - val_accuracy: 0.9138\n",
      "Epoch 19/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.5038 - accuracy: 0.9763 - val_loss: 0.6491 - val_accuracy: 0.9152\n",
      "Epoch 20/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4956 - accuracy: 0.9771 - val_loss: 0.6406 - val_accuracy: 0.9159\n",
      "Epoch 21/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4791 - accuracy: 0.9805 - val_loss: 0.6334 - val_accuracy: 0.9166\n",
      "Epoch 22/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4780 - accuracy: 0.9785 - val_loss: 0.6267 - val_accuracy: 0.9166\n",
      "Epoch 23/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4733 - accuracy: 0.9791 - val_loss: 0.6210 - val_accuracy: 0.9166\n",
      "Epoch 24/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4585 - accuracy: 0.9795 - val_loss: 0.6152 - val_accuracy: 0.9179\n",
      "Epoch 25/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4597 - accuracy: 0.9800 - val_loss: 0.6106 - val_accuracy: 0.9193\n",
      "Epoch 26/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4490 - accuracy: 0.9806 - val_loss: 0.6062 - val_accuracy: 0.9200\n",
      "Epoch 27/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4474 - accuracy: 0.9805 - val_loss: 0.6020 - val_accuracy: 0.9193\n",
      "Epoch 28/30\n",
      "405/405 [==============================] - 14s 34ms/step - loss: 0.4445 - accuracy: 0.9810 - val_loss: 0.5986 - val_accuracy: 0.9193\n",
      "Epoch 29/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4383 - accuracy: 0.9824 - val_loss: 0.5953 - val_accuracy: 0.9214\n",
      "Epoch 30/30\n",
      "405/405 [==============================] - 3s 8ms/step - loss: 0.4321 - accuracy: 0.9826 - val_loss: 0.5924 - val_accuracy: 0.9207\n",
      "Đã train xong Fold  0\n",
      "TRAIN: [    0     1     2 ... 14371 14372 14374] TEST: [   13    38    44 ... 14369 14370 14373]\n",
      "Epoch 1/30\n",
      "405/405 [==============================] - 21s 20ms/step - loss: 2.9652 - accuracy: 0.4958 - val_loss: 2.2136 - val_accuracy: 0.6599\n",
      "Epoch 2/30\n",
      "405/405 [==============================] - 3s 8ms/step - loss: 2.0148 - accuracy: 0.7337 - val_loss: 1.6861 - val_accuracy: 0.7719\n",
      "Epoch 3/30\n",
      "405/405 [==============================] - 3s 8ms/step - loss: 1.5436 - accuracy: 0.8154 - val_loss: 1.3864 - val_accuracy: 0.8268\n",
      "Epoch 4/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 1.2428 - accuracy: 0.8772 - val_loss: 1.2013 - val_accuracy: 0.8609\n",
      "Epoch 5/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 1.0620 - accuracy: 0.9071 - val_loss: 1.0783 - val_accuracy: 0.8818\n",
      "Epoch 6/30\n",
      "405/405 [==============================] - 3s 8ms/step - loss: 0.9506 - accuracy: 0.9272 - val_loss: 0.9911 - val_accuracy: 0.8922\n",
      "Epoch 7/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.8504 - accuracy: 0.9426 - val_loss: 0.9258 - val_accuracy: 0.8992\n",
      "Epoch 8/30\n",
      "405/405 [==============================] - 3s 8ms/step - loss: 0.7962 - accuracy: 0.9478 - val_loss: 0.8752 - val_accuracy: 0.9026\n",
      "Epoch 9/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.7378 - accuracy: 0.9572 - val_loss: 0.8345 - val_accuracy: 0.9047\n",
      "Epoch 10/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.6901 - accuracy: 0.9588 - val_loss: 0.8009 - val_accuracy: 0.9061\n",
      "Epoch 11/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.9639 - val_loss: 0.7728 - val_accuracy: 0.9096\n",
      "Epoch 12/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.6238 - accuracy: 0.9670 - val_loss: 0.7487 - val_accuracy: 0.9103\n",
      "Epoch 13/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.6062 - accuracy: 0.9676 - val_loss: 0.7283 - val_accuracy: 0.9096\n",
      "Epoch 14/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.5813 - accuracy: 0.9681 - val_loss: 0.7103 - val_accuracy: 0.9103\n",
      "Epoch 15/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.5676 - accuracy: 0.9681 - val_loss: 0.6943 - val_accuracy: 0.9110\n",
      "Epoch 16/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.5492 - accuracy: 0.9715 - val_loss: 0.6806 - val_accuracy: 0.9117\n",
      "Epoch 17/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.5331 - accuracy: 0.9727 - val_loss: 0.6681 - val_accuracy: 0.9117\n",
      "Epoch 18/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.5208 - accuracy: 0.9761 - val_loss: 0.6576 - val_accuracy: 0.9096\n",
      "Epoch 19/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.5096 - accuracy: 0.9750 - val_loss: 0.6478 - val_accuracy: 0.9117\n",
      "Epoch 20/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4943 - accuracy: 0.9780 - val_loss: 0.6392 - val_accuracy: 0.9117\n",
      "Epoch 21/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4834 - accuracy: 0.9773 - val_loss: 0.6314 - val_accuracy: 0.9124\n",
      "Epoch 22/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4760 - accuracy: 0.9797 - val_loss: 0.6243 - val_accuracy: 0.9117\n",
      "Epoch 23/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4730 - accuracy: 0.9778 - val_loss: 0.6181 - val_accuracy: 0.9117\n",
      "Epoch 24/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4639 - accuracy: 0.9789 - val_loss: 0.6123 - val_accuracy: 0.9117\n",
      "Epoch 25/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4570 - accuracy: 0.9806 - val_loss: 0.6073 - val_accuracy: 0.9145\n",
      "Epoch 26/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4517 - accuracy: 0.9795 - val_loss: 0.6026 - val_accuracy: 0.9110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4499 - accuracy: 0.9823 - val_loss: 0.5985 - val_accuracy: 0.9124\n",
      "Epoch 28/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4426 - accuracy: 0.9827 - val_loss: 0.5947 - val_accuracy: 0.9124\n",
      "Epoch 29/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4383 - accuracy: 0.9816 - val_loss: 0.5914 - val_accuracy: 0.9117\n",
      "Epoch 30/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4312 - accuracy: 0.9832 - val_loss: 0.5881 - val_accuracy: 0.9131\n",
      "Đã train xong Fold  1\n",
      "TRAIN: [    0     1     2 ... 14372 14373 14374] TEST: [   29    30    33 ... 14338 14364 14366]\n",
      "Epoch 1/30\n",
      "405/405 [==============================] - 14s 9ms/step - loss: 2.9650 - accuracy: 0.4974 - val_loss: 2.2133 - val_accuracy: 0.6829\n",
      "Epoch 2/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 2.0178 - accuracy: 0.7410 - val_loss: 1.6893 - val_accuracy: 0.7698\n",
      "Epoch 3/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 1.5268 - accuracy: 0.8241 - val_loss: 1.3914 - val_accuracy: 0.8164\n",
      "Epoch 4/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 1.2436 - accuracy: 0.8768 - val_loss: 1.2076 - val_accuracy: 0.8449\n",
      "Epoch 5/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 1.0593 - accuracy: 0.9053 - val_loss: 1.0856 - val_accuracy: 0.8686\n",
      "Epoch 6/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.9322 - accuracy: 0.9347 - val_loss: 0.9996 - val_accuracy: 0.8866\n",
      "Epoch 7/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.8552 - accuracy: 0.9442 - val_loss: 0.9359 - val_accuracy: 0.8936\n",
      "Epoch 8/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.7797 - accuracy: 0.9508 - val_loss: 0.8866 - val_accuracy: 0.8985\n",
      "Epoch 9/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.7284 - accuracy: 0.9552 - val_loss: 0.8471 - val_accuracy: 0.9047\n",
      "Epoch 10/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.6884 - accuracy: 0.9615 - val_loss: 0.8149 - val_accuracy: 0.9026\n",
      "Epoch 11/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.6551 - accuracy: 0.9611 - val_loss: 0.7878 - val_accuracy: 0.9054\n",
      "Epoch 12/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.6263 - accuracy: 0.9656 - val_loss: 0.7649 - val_accuracy: 0.9082\n",
      "Epoch 13/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.6006 - accuracy: 0.9691 - val_loss: 0.7455 - val_accuracy: 0.9082\n",
      "Epoch 14/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.5831 - accuracy: 0.9675 - val_loss: 0.7283 - val_accuracy: 0.9096\n",
      "Epoch 15/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.5633 - accuracy: 0.9716 - val_loss: 0.7134 - val_accuracy: 0.9103\n",
      "Epoch 16/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.5466 - accuracy: 0.9726 - val_loss: 0.7004 - val_accuracy: 0.9131\n",
      "Epoch 17/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.5328 - accuracy: 0.9723 - val_loss: 0.6889 - val_accuracy: 0.9096\n",
      "Epoch 18/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.5147 - accuracy: 0.9757 - val_loss: 0.6786 - val_accuracy: 0.9103\n",
      "Epoch 19/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.5041 - accuracy: 0.9732 - val_loss: 0.6695 - val_accuracy: 0.9110\n",
      "Epoch 20/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4917 - accuracy: 0.9765 - val_loss: 0.6614 - val_accuracy: 0.9110\n",
      "Epoch 21/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4801 - accuracy: 0.9800 - val_loss: 0.6539 - val_accuracy: 0.9103\n",
      "Epoch 22/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4760 - accuracy: 0.9781 - val_loss: 0.6477 - val_accuracy: 0.9089\n",
      "Epoch 23/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4650 - accuracy: 0.9799 - val_loss: 0.6417 - val_accuracy: 0.9096\n",
      "Epoch 24/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4586 - accuracy: 0.9797 - val_loss: 0.6369 - val_accuracy: 0.9089\n",
      "Epoch 25/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4540 - accuracy: 0.9798 - val_loss: 0.6319 - val_accuracy: 0.9103\n",
      "Epoch 26/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4501 - accuracy: 0.9826 - val_loss: 0.6278 - val_accuracy: 0.9103\n",
      "Epoch 27/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4486 - accuracy: 0.9796 - val_loss: 0.6239 - val_accuracy: 0.9110\n",
      "Epoch 28/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4388 - accuracy: 0.9820 - val_loss: 0.6202 - val_accuracy: 0.9096\n",
      "Epoch 29/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4328 - accuracy: 0.9835 - val_loss: 0.6169 - val_accuracy: 0.9103\n",
      "Epoch 30/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4332 - accuracy: 0.9832 - val_loss: 0.6145 - val_accuracy: 0.9103\n",
      "Đã train xong Fold  2\n",
      "TRAIN: [    0     1     2 ... 14372 14373 14374] TEST: [    7    14    23 ... 14345 14348 14359]\n",
      "Epoch 1/30\n",
      "405/405 [==============================] - 7s 10ms/step - loss: 2.9666 - accuracy: 0.4954 - val_loss: 2.2209 - val_accuracy: 0.6704\n",
      "Epoch 2/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 2.0161 - accuracy: 0.7450 - val_loss: 1.6947 - val_accuracy: 0.7698\n",
      "Epoch 3/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 1.5304 - accuracy: 0.8236 - val_loss: 1.3950 - val_accuracy: 0.8102\n",
      "Epoch 4/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 1.2345 - accuracy: 0.8791 - val_loss: 1.2108 - val_accuracy: 0.8470\n",
      "Epoch 5/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 1.0595 - accuracy: 0.9105 - val_loss: 1.0882 - val_accuracy: 0.8623\n",
      "Epoch 6/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.9385 - accuracy: 0.9287 - val_loss: 1.0018 - val_accuracy: 0.8755\n",
      "Epoch 7/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.8588 - accuracy: 0.9383 - val_loss: 0.9374 - val_accuracy: 0.8839\n",
      "Epoch 8/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.7871 - accuracy: 0.9484 - val_loss: 0.8877 - val_accuracy: 0.8880\n",
      "Epoch 9/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.7350 - accuracy: 0.9516 - val_loss: 0.8476 - val_accuracy: 0.8894\n",
      "Epoch 10/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.6919 - accuracy: 0.9565 - val_loss: 0.8149 - val_accuracy: 0.8971\n",
      "Epoch 11/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.6558 - accuracy: 0.9621 - val_loss: 0.7875 - val_accuracy: 0.8999\n",
      "Epoch 12/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.6399 - accuracy: 0.9639 - val_loss: 0.7643 - val_accuracy: 0.9033\n",
      "Epoch 13/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.6050 - accuracy: 0.9686 - val_loss: 0.7442 - val_accuracy: 0.9075\n",
      "Epoch 14/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.5778 - accuracy: 0.9727 - val_loss: 0.7269 - val_accuracy: 0.9089\n",
      "Epoch 15/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.5666 - accuracy: 0.9708 - val_loss: 0.7118 - val_accuracy: 0.9089\n",
      "Epoch 16/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.5473 - accuracy: 0.9705 - val_loss: 0.6985 - val_accuracy: 0.9075\n",
      "Epoch 17/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.5246 - accuracy: 0.9768 - val_loss: 0.6869 - val_accuracy: 0.9089\n",
      "Epoch 18/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.5127 - accuracy: 0.9752 - val_loss: 0.6766 - val_accuracy: 0.9096\n",
      "Epoch 19/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.5070 - accuracy: 0.9755 - val_loss: 0.6673 - val_accuracy: 0.9103\n",
      "Epoch 20/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4951 - accuracy: 0.9766 - val_loss: 0.6591 - val_accuracy: 0.9103\n",
      "Epoch 21/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4910 - accuracy: 0.9760 - val_loss: 0.6518 - val_accuracy: 0.9124\n",
      "Epoch 22/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4780 - accuracy: 0.9770 - val_loss: 0.6453 - val_accuracy: 0.9131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4684 - accuracy: 0.9801 - val_loss: 0.6395 - val_accuracy: 0.9131\n",
      "Epoch 24/30\n",
      "405/405 [==============================] - 22s 54ms/step - loss: 0.4612 - accuracy: 0.9809 - val_loss: 0.6342 - val_accuracy: 0.9124\n",
      "Epoch 25/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4593 - accuracy: 0.9783 - val_loss: 0.6296 - val_accuracy: 0.9124\n",
      "Epoch 26/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4519 - accuracy: 0.9795 - val_loss: 0.6253 - val_accuracy: 0.9124\n",
      "Epoch 27/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4444 - accuracy: 0.9813 - val_loss: 0.6215 - val_accuracy: 0.9117\n",
      "Epoch 28/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4389 - accuracy: 0.9818 - val_loss: 0.6180 - val_accuracy: 0.9117\n",
      "Epoch 29/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4364 - accuracy: 0.9834 - val_loss: 0.6149 - val_accuracy: 0.9117\n",
      "Epoch 30/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4315 - accuracy: 0.9811 - val_loss: 0.6122 - val_accuracy: 0.9110\n",
      "Đã train xong Fold  3\n",
      "TRAIN: [    0     1     2 ... 14370 14372 14373] TEST: [    6    18    28 ... 14355 14371 14374]\n",
      "Epoch 1/30\n",
      "405/405 [==============================] - 5s 9ms/step - loss: 2.9668 - accuracy: 0.4737 - val_loss: 2.2215 - val_accuracy: 0.6808\n",
      "Epoch 2/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 2.0156 - accuracy: 0.7388 - val_loss: 1.6933 - val_accuracy: 0.7670\n",
      "Epoch 3/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 1.5294 - accuracy: 0.8232 - val_loss: 1.3923 - val_accuracy: 0.8192\n",
      "Epoch 4/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 1.2475 - accuracy: 0.8735 - val_loss: 1.2061 - val_accuracy: 0.8442\n",
      "Epoch 5/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 1.0581 - accuracy: 0.9098 - val_loss: 1.0822 - val_accuracy: 0.8658\n",
      "Epoch 6/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.9447 - accuracy: 0.9276 - val_loss: 0.9946 - val_accuracy: 0.8707\n",
      "Epoch 7/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.8545 - accuracy: 0.9415 - val_loss: 0.9293 - val_accuracy: 0.8846\n",
      "Epoch 8/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.7842 - accuracy: 0.9492 - val_loss: 0.8788 - val_accuracy: 0.8908\n",
      "Epoch 9/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.7298 - accuracy: 0.9560 - val_loss: 0.8385 - val_accuracy: 0.8950\n",
      "Epoch 10/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.6942 - accuracy: 0.9606 - val_loss: 0.8055 - val_accuracy: 0.8971\n",
      "Epoch 11/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.6573 - accuracy: 0.9635 - val_loss: 0.7778 - val_accuracy: 0.8992\n",
      "Epoch 12/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.6381 - accuracy: 0.9633 - val_loss: 0.7544 - val_accuracy: 0.9013\n",
      "Epoch 13/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.6040 - accuracy: 0.9682 - val_loss: 0.7342 - val_accuracy: 0.9047\n",
      "Epoch 14/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.5846 - accuracy: 0.9694 - val_loss: 0.7167 - val_accuracy: 0.9026\n",
      "Epoch 15/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.5679 - accuracy: 0.9678 - val_loss: 0.7013 - val_accuracy: 0.9040\n",
      "Epoch 16/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.5460 - accuracy: 0.9745 - val_loss: 0.6879 - val_accuracy: 0.9075\n",
      "Epoch 17/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.5237 - accuracy: 0.9763 - val_loss: 0.6760 - val_accuracy: 0.9061\n",
      "Epoch 18/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.5195 - accuracy: 0.9748 - val_loss: 0.6655 - val_accuracy: 0.9068\n",
      "Epoch 19/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.5052 - accuracy: 0.9755 - val_loss: 0.6562 - val_accuracy: 0.9068\n",
      "Epoch 20/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4894 - accuracy: 0.9771 - val_loss: 0.6478 - val_accuracy: 0.9075\n",
      "Epoch 21/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4835 - accuracy: 0.9785 - val_loss: 0.6403 - val_accuracy: 0.9082\n",
      "Epoch 22/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4770 - accuracy: 0.9777 - val_loss: 0.6335 - val_accuracy: 0.9054\n",
      "Epoch 23/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4710 - accuracy: 0.9776 - val_loss: 0.6277 - val_accuracy: 0.9061\n",
      "Epoch 24/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4641 - accuracy: 0.9798 - val_loss: 0.6221 - val_accuracy: 0.9061\n",
      "Epoch 25/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4546 - accuracy: 0.9817 - val_loss: 0.6172 - val_accuracy: 0.9054\n",
      "Epoch 26/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4548 - accuracy: 0.9797 - val_loss: 0.6132 - val_accuracy: 0.9047\n",
      "Epoch 27/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4450 - accuracy: 0.9823 - val_loss: 0.6090 - val_accuracy: 0.9061\n",
      "Epoch 28/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4410 - accuracy: 0.9817 - val_loss: 0.6053 - val_accuracy: 0.9061\n",
      "Epoch 29/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4374 - accuracy: 0.9826 - val_loss: 0.6021 - val_accuracy: 0.9061\n",
      "Epoch 30/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4311 - accuracy: 0.9816 - val_loss: 0.5992 - val_accuracy: 0.9054\n",
      "Đã train xong Fold  4\n",
      "TRAIN: [    0     1     2 ... 14372 14373 14374] TEST: [    8    17    26 ... 14329 14357 14358]\n",
      "Epoch 1/30\n",
      "405/405 [==============================] - 6s 9ms/step - loss: 2.9626 - accuracy: 0.5000 - val_loss: 2.2172 - val_accuracy: 0.6743\n",
      "Epoch 2/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 2.0179 - accuracy: 0.7330 - val_loss: 1.6965 - val_accuracy: 0.7662\n",
      "Epoch 3/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 1.5213 - accuracy: 0.8241 - val_loss: 1.3997 - val_accuracy: 0.8114\n",
      "Epoch 4/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 1.2377 - accuracy: 0.8748 - val_loss: 1.2169 - val_accuracy: 0.8497\n",
      "Epoch 5/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 1.0639 - accuracy: 0.9068 - val_loss: 1.0950 - val_accuracy: 0.8692\n",
      "Epoch 6/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.9382 - accuracy: 0.9287 - val_loss: 1.0085 - val_accuracy: 0.8803\n",
      "Epoch 7/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.8550 - accuracy: 0.9381 - val_loss: 0.9442 - val_accuracy: 0.8900\n",
      "Epoch 8/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.7814 - accuracy: 0.9486 - val_loss: 0.8941 - val_accuracy: 0.8935\n",
      "Epoch 9/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.7311 - accuracy: 0.9570 - val_loss: 0.8539 - val_accuracy: 0.8956\n",
      "Epoch 10/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.6862 - accuracy: 0.9609 - val_loss: 0.8212 - val_accuracy: 0.9033\n",
      "Epoch 11/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.6607 - accuracy: 0.9618 - val_loss: 0.7935 - val_accuracy: 0.9033\n",
      "Epoch 12/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.6253 - accuracy: 0.9676 - val_loss: 0.7699 - val_accuracy: 0.9040\n",
      "Epoch 13/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.5938 - accuracy: 0.9696 - val_loss: 0.7498 - val_accuracy: 0.9074\n",
      "Epoch 14/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.5790 - accuracy: 0.9683 - val_loss: 0.7322 - val_accuracy: 0.9095\n",
      "Epoch 15/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.5584 - accuracy: 0.9720 - val_loss: 0.7167 - val_accuracy: 0.9095\n",
      "Epoch 16/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.5513 - accuracy: 0.9723 - val_loss: 0.7034 - val_accuracy: 0.9109\n",
      "Epoch 17/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.5291 - accuracy: 0.9759 - val_loss: 0.6913 - val_accuracy: 0.9109\n",
      "Epoch 18/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.5224 - accuracy: 0.9755 - val_loss: 0.6807 - val_accuracy: 0.9137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.5037 - accuracy: 0.9779 - val_loss: 0.6711 - val_accuracy: 0.9144\n",
      "Epoch 20/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4915 - accuracy: 0.9775 - val_loss: 0.6628 - val_accuracy: 0.9137\n",
      "Epoch 21/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4821 - accuracy: 0.9775 - val_loss: 0.6553 - val_accuracy: 0.9130\n",
      "Epoch 22/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4748 - accuracy: 0.9796 - val_loss: 0.6484 - val_accuracy: 0.9144\n",
      "Epoch 23/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4705 - accuracy: 0.9807 - val_loss: 0.6425 - val_accuracy: 0.9137\n",
      "Epoch 24/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4582 - accuracy: 0.9819 - val_loss: 0.6369 - val_accuracy: 0.9144\n",
      "Epoch 25/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4539 - accuracy: 0.9818 - val_loss: 0.6321 - val_accuracy: 0.9137\n",
      "Epoch 26/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4518 - accuracy: 0.9823 - val_loss: 0.6275 - val_accuracy: 0.9123\n",
      "Epoch 27/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4461 - accuracy: 0.9840 - val_loss: 0.6235 - val_accuracy: 0.9123\n",
      "Epoch 28/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4436 - accuracy: 0.9805 - val_loss: 0.6199 - val_accuracy: 0.9130\n",
      "Epoch 29/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4339 - accuracy: 0.9830 - val_loss: 0.6163 - val_accuracy: 0.9144\n",
      "Epoch 30/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4317 - accuracy: 0.9820 - val_loss: 0.6135 - val_accuracy: 0.9137\n",
      "Đã train xong Fold  5\n",
      "TRAIN: [    0     3     4 ... 14372 14373 14374] TEST: [    1     2    12 ... 14334 14354 14360]\n",
      "Epoch 1/30\n",
      "405/405 [==============================] - 6s 10ms/step - loss: 2.9674 - accuracy: 0.5138 - val_loss: 2.2162 - val_accuracy: 0.6813\n",
      "Epoch 2/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 2.0299 - accuracy: 0.7296 - val_loss: 1.6909 - val_accuracy: 0.7808\n",
      "Epoch 3/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 1.5367 - accuracy: 0.8150 - val_loss: 1.3899 - val_accuracy: 0.8267\n",
      "Epoch 4/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 1.2457 - accuracy: 0.8661 - val_loss: 1.2030 - val_accuracy: 0.8553\n",
      "Epoch 5/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 1.0662 - accuracy: 0.9071 - val_loss: 1.0783 - val_accuracy: 0.8768\n",
      "Epoch 6/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.9446 - accuracy: 0.9287 - val_loss: 0.9898 - val_accuracy: 0.8866\n",
      "Epoch 7/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.8449 - accuracy: 0.9407 - val_loss: 0.9238 - val_accuracy: 0.8928\n",
      "Epoch 8/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.7918 - accuracy: 0.9484 - val_loss: 0.8726 - val_accuracy: 0.8970\n",
      "Epoch 9/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.7289 - accuracy: 0.9528 - val_loss: 0.8317 - val_accuracy: 0.8998\n",
      "Epoch 10/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.6876 - accuracy: 0.9598 - val_loss: 0.7979 - val_accuracy: 0.9088\n",
      "Epoch 11/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.6593 - accuracy: 0.9611 - val_loss: 0.7696 - val_accuracy: 0.9123\n",
      "Epoch 12/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.6245 - accuracy: 0.9666 - val_loss: 0.7457 - val_accuracy: 0.9116\n",
      "Epoch 13/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.6049 - accuracy: 0.9668 - val_loss: 0.7248 - val_accuracy: 0.9144\n",
      "Epoch 14/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.5889 - accuracy: 0.9679 - val_loss: 0.7070 - val_accuracy: 0.9165\n",
      "Epoch 15/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.5646 - accuracy: 0.9705 - val_loss: 0.6913 - val_accuracy: 0.9172\n",
      "Epoch 16/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.5475 - accuracy: 0.9714 - val_loss: 0.6775 - val_accuracy: 0.9193\n",
      "Epoch 17/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.5356 - accuracy: 0.9688 - val_loss: 0.6652 - val_accuracy: 0.9193\n",
      "Epoch 18/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.5258 - accuracy: 0.9700 - val_loss: 0.6544 - val_accuracy: 0.9193\n",
      "Epoch 19/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.5041 - accuracy: 0.9745 - val_loss: 0.6447 - val_accuracy: 0.9207\n",
      "Epoch 20/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.5022 - accuracy: 0.9738 - val_loss: 0.6362 - val_accuracy: 0.9207\n",
      "Epoch 21/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4875 - accuracy: 0.9746 - val_loss: 0.6285 - val_accuracy: 0.9207\n",
      "Epoch 22/30\n",
      "405/405 [==============================] - 8s 20ms/step - loss: 0.4776 - accuracy: 0.9789 - val_loss: 0.6216 - val_accuracy: 0.9207\n",
      "Epoch 23/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4658 - accuracy: 0.9810 - val_loss: 0.6154 - val_accuracy: 0.9214\n",
      "Epoch 24/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4697 - accuracy: 0.9789 - val_loss: 0.6100 - val_accuracy: 0.9214\n",
      "Epoch 25/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4579 - accuracy: 0.9793 - val_loss: 0.6049 - val_accuracy: 0.9221\n",
      "Epoch 26/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4477 - accuracy: 0.9819 - val_loss: 0.6003 - val_accuracy: 0.9207\n",
      "Epoch 27/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4437 - accuracy: 0.9816 - val_loss: 0.5961 - val_accuracy: 0.9200\n",
      "Epoch 28/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4413 - accuracy: 0.9818 - val_loss: 0.5926 - val_accuracy: 0.9207\n",
      "Epoch 29/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4399 - accuracy: 0.9821 - val_loss: 0.5892 - val_accuracy: 0.9207\n",
      "Epoch 30/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4353 - accuracy: 0.9815 - val_loss: 0.5864 - val_accuracy: 0.9214\n",
      "Đã train xong Fold  6\n",
      "TRAIN: [    0     1     2 ... 14372 14373 14374] TEST: [    5    10    19 ... 14356 14361 14368]\n",
      "Epoch 1/30\n",
      "405/405 [==============================] - 6s 11ms/step - loss: 2.9646 - accuracy: 0.4750 - val_loss: 2.2300 - val_accuracy: 0.6611\n",
      "Epoch 2/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 2.0174 - accuracy: 0.7345 - val_loss: 1.7099 - val_accuracy: 0.7606\n",
      "Epoch 3/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 1.5316 - accuracy: 0.8197 - val_loss: 1.4135 - val_accuracy: 0.8093\n",
      "Epoch 4/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 1.2401 - accuracy: 0.8750 - val_loss: 1.2302 - val_accuracy: 0.8358\n",
      "Epoch 5/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 1.0602 - accuracy: 0.9070 - val_loss: 1.1078 - val_accuracy: 0.8657\n",
      "Epoch 6/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.9363 - accuracy: 0.9294 - val_loss: 1.0206 - val_accuracy: 0.8803\n",
      "Epoch 7/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.8473 - accuracy: 0.9424 - val_loss: 0.9551 - val_accuracy: 0.8900\n",
      "Epoch 8/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.7837 - accuracy: 0.9498 - val_loss: 0.9042 - val_accuracy: 0.8949\n",
      "Epoch 9/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.7333 - accuracy: 0.9534 - val_loss: 0.8632 - val_accuracy: 0.8956\n",
      "Epoch 10/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.6879 - accuracy: 0.9633 - val_loss: 0.8296 - val_accuracy: 0.9026\n",
      "Epoch 11/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.6560 - accuracy: 0.9637 - val_loss: 0.8012 - val_accuracy: 0.9068\n",
      "Epoch 12/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.6266 - accuracy: 0.9630 - val_loss: 0.7768 - val_accuracy: 0.9088\n",
      "Epoch 13/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.6005 - accuracy: 0.9692 - val_loss: 0.7561 - val_accuracy: 0.9095\n",
      "Epoch 14/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.5879 - accuracy: 0.9670 - val_loss: 0.7380 - val_accuracy: 0.9102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.5596 - accuracy: 0.9706 - val_loss: 0.7218 - val_accuracy: 0.9095\n",
      "Epoch 16/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.5477 - accuracy: 0.9717 - val_loss: 0.7080 - val_accuracy: 0.9109\n",
      "Epoch 17/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.5250 - accuracy: 0.9745 - val_loss: 0.6956 - val_accuracy: 0.9102\n",
      "Epoch 18/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.5180 - accuracy: 0.9731 - val_loss: 0.6844 - val_accuracy: 0.9109\n",
      "Epoch 19/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.5078 - accuracy: 0.9769 - val_loss: 0.6748 - val_accuracy: 0.9144\n",
      "Epoch 20/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4931 - accuracy: 0.9769 - val_loss: 0.6662 - val_accuracy: 0.9130\n",
      "Epoch 21/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4869 - accuracy: 0.9770 - val_loss: 0.6582 - val_accuracy: 0.9144\n",
      "Epoch 22/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4762 - accuracy: 0.9757 - val_loss: 0.6512 - val_accuracy: 0.9151\n",
      "Epoch 23/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4670 - accuracy: 0.9808 - val_loss: 0.6446 - val_accuracy: 0.9165\n",
      "Epoch 24/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4542 - accuracy: 0.9808 - val_loss: 0.6389 - val_accuracy: 0.9172\n",
      "Epoch 25/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4562 - accuracy: 0.9805 - val_loss: 0.6336 - val_accuracy: 0.9179\n",
      "Epoch 26/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4473 - accuracy: 0.9810 - val_loss: 0.6286 - val_accuracy: 0.9193\n",
      "Epoch 27/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4460 - accuracy: 0.9803 - val_loss: 0.6244 - val_accuracy: 0.9200\n",
      "Epoch 28/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4372 - accuracy: 0.9811 - val_loss: 0.6205 - val_accuracy: 0.9214\n",
      "Epoch 29/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4365 - accuracy: 0.9834 - val_loss: 0.6170 - val_accuracy: 0.9221\n",
      "Epoch 30/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4293 - accuracy: 0.9843 - val_loss: 0.6139 - val_accuracy: 0.9241\n",
      "Đã train xong Fold  7\n",
      "TRAIN: [    1     2     3 ... 14372 14373 14374] TEST: [    0     4     9 ... 14337 14347 14352]\n",
      "Epoch 1/30\n",
      "405/405 [==============================] - 13s 21ms/step - loss: 2.9662 - accuracy: 0.4642 - val_loss: 2.2172 - val_accuracy: 0.6562\n",
      "Epoch 2/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 2.0129 - accuracy: 0.7338 - val_loss: 1.6916 - val_accuracy: 0.7627\n",
      "Epoch 3/30\n",
      "405/405 [==============================] - 3s 8ms/step - loss: 1.5307 - accuracy: 0.8209 - val_loss: 1.3902 - val_accuracy: 0.8219\n",
      "Epoch 4/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 1.2375 - accuracy: 0.8768 - val_loss: 1.2030 - val_accuracy: 0.8566\n",
      "Epoch 5/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 1.0663 - accuracy: 0.9046 - val_loss: 1.0774 - val_accuracy: 0.8768\n",
      "Epoch 6/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.9349 - accuracy: 0.9290 - val_loss: 0.9883 - val_accuracy: 0.8900\n",
      "Epoch 7/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.8591 - accuracy: 0.9421 - val_loss: 0.9217 - val_accuracy: 0.8998\n",
      "Epoch 8/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.7753 - accuracy: 0.9492 - val_loss: 0.8700 - val_accuracy: 0.9102\n",
      "Epoch 9/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.7366 - accuracy: 0.9533 - val_loss: 0.8285 - val_accuracy: 0.9144\n",
      "Epoch 10/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.7006 - accuracy: 0.9568 - val_loss: 0.7945 - val_accuracy: 0.9172\n",
      "Epoch 11/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.6562 - accuracy: 0.9598 - val_loss: 0.7657 - val_accuracy: 0.9179\n",
      "Epoch 12/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.6296 - accuracy: 0.9648 - val_loss: 0.7413 - val_accuracy: 0.9200\n",
      "Epoch 13/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.6045 - accuracy: 0.9660 - val_loss: 0.7204 - val_accuracy: 0.9207\n",
      "Epoch 14/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.5793 - accuracy: 0.9693 - val_loss: 0.7022 - val_accuracy: 0.9221\n",
      "Epoch 15/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.5619 - accuracy: 0.9724 - val_loss: 0.6862 - val_accuracy: 0.9248\n",
      "Epoch 16/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.5481 - accuracy: 0.9724 - val_loss: 0.6722 - val_accuracy: 0.9241\n",
      "Epoch 17/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.5342 - accuracy: 0.9744 - val_loss: 0.6598 - val_accuracy: 0.9262\n",
      "Epoch 18/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.5261 - accuracy: 0.9766 - val_loss: 0.6486 - val_accuracy: 0.9255\n",
      "Epoch 19/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.5109 - accuracy: 0.9746 - val_loss: 0.6387 - val_accuracy: 0.9255\n",
      "Epoch 20/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4988 - accuracy: 0.9756 - val_loss: 0.6301 - val_accuracy: 0.9248\n",
      "Epoch 21/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4917 - accuracy: 0.9786 - val_loss: 0.6222 - val_accuracy: 0.9248\n",
      "Epoch 22/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4833 - accuracy: 0.9767 - val_loss: 0.6153 - val_accuracy: 0.9255\n",
      "Epoch 23/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4768 - accuracy: 0.9772 - val_loss: 0.6088 - val_accuracy: 0.9235\n",
      "Epoch 24/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4618 - accuracy: 0.9800 - val_loss: 0.6031 - val_accuracy: 0.9248\n",
      "Epoch 25/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4625 - accuracy: 0.9797 - val_loss: 0.5978 - val_accuracy: 0.9255\n",
      "Epoch 26/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4476 - accuracy: 0.9821 - val_loss: 0.5932 - val_accuracy: 0.9269\n",
      "Epoch 27/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4501 - accuracy: 0.9790 - val_loss: 0.5887 - val_accuracy: 0.9241\n",
      "Epoch 28/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4408 - accuracy: 0.9822 - val_loss: 0.5851 - val_accuracy: 0.9248\n",
      "Epoch 29/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4395 - accuracy: 0.9818 - val_loss: 0.5817 - val_accuracy: 0.9269\n",
      "Epoch 30/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4273 - accuracy: 0.9825 - val_loss: 0.5782 - val_accuracy: 0.9262\n",
      "Đã train xong Fold  8\n",
      "TRAIN: [    0     1     2 ... 14372 14373 14374] TEST: [    3    24    31 ... 14344 14362 14363]\n",
      "Epoch 1/30\n",
      "405/405 [==============================] - 5s 9ms/step - loss: 2.9661 - accuracy: 0.4846 - val_loss: 2.2191 - val_accuracy: 0.6778\n",
      "Epoch 2/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 2.0103 - accuracy: 0.7344 - val_loss: 1.6936 - val_accuracy: 0.7738\n",
      "Epoch 3/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 1.5377 - accuracy: 0.8199 - val_loss: 1.3944 - val_accuracy: 0.8198\n",
      "Epoch 4/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 1.2428 - accuracy: 0.8764 - val_loss: 1.2103 - val_accuracy: 0.8483\n",
      "Epoch 5/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 1.0658 - accuracy: 0.9072 - val_loss: 1.0879 - val_accuracy: 0.8727\n",
      "Epoch 6/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.9459 - accuracy: 0.9309 - val_loss: 1.0008 - val_accuracy: 0.8838\n",
      "Epoch 7/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.8521 - accuracy: 0.9433 - val_loss: 0.9363 - val_accuracy: 0.8907\n",
      "Epoch 8/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.7848 - accuracy: 0.9506 - val_loss: 0.8863 - val_accuracy: 0.8984\n",
      "Epoch 9/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.7288 - accuracy: 0.9578 - val_loss: 0.8461 - val_accuracy: 0.9054\n",
      "Epoch 10/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.6911 - accuracy: 0.9604 - val_loss: 0.8133 - val_accuracy: 0.9081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "405/405 [==============================] - 2s 6ms/step - loss: 0.6579 - accuracy: 0.9630 - val_loss: 0.7857 - val_accuracy: 0.9109\n",
      "Epoch 12/30\n",
      "405/405 [==============================] - 2s 6ms/step - loss: 0.6277 - accuracy: 0.9658 - val_loss: 0.7622 - val_accuracy: 0.9130\n",
      "Epoch 13/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.6020 - accuracy: 0.9679 - val_loss: 0.7420 - val_accuracy: 0.9144\n",
      "Epoch 14/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.5787 - accuracy: 0.9681 - val_loss: 0.7245 - val_accuracy: 0.9158\n",
      "Epoch 15/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.5614 - accuracy: 0.9720 - val_loss: 0.7093 - val_accuracy: 0.9158\n",
      "Epoch 16/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.5391 - accuracy: 0.9737 - val_loss: 0.6958 - val_accuracy: 0.9186\n",
      "Epoch 17/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.5328 - accuracy: 0.9720 - val_loss: 0.6839 - val_accuracy: 0.9172\n",
      "Epoch 18/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.5165 - accuracy: 0.9751 - val_loss: 0.6733 - val_accuracy: 0.9165\n",
      "Epoch 19/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.5011 - accuracy: 0.9776 - val_loss: 0.6638 - val_accuracy: 0.9179\n",
      "Epoch 20/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4975 - accuracy: 0.9763 - val_loss: 0.6553 - val_accuracy: 0.9172\n",
      "Epoch 21/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4839 - accuracy: 0.9767 - val_loss: 0.6478 - val_accuracy: 0.9172\n",
      "Epoch 22/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4795 - accuracy: 0.9779 - val_loss: 0.6411 - val_accuracy: 0.9165\n",
      "Epoch 23/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4730 - accuracy: 0.9778 - val_loss: 0.6351 - val_accuracy: 0.9179\n",
      "Epoch 24/30\n",
      "405/405 [==============================] - 12s 30ms/step - loss: 0.4652 - accuracy: 0.9776 - val_loss: 0.6295 - val_accuracy: 0.9186\n",
      "Epoch 25/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4579 - accuracy: 0.9803 - val_loss: 0.6247 - val_accuracy: 0.9179\n",
      "Epoch 26/30\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.4524 - accuracy: 0.9811 - val_loss: 0.6202 - val_accuracy: 0.9172\n",
      "Epoch 27/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4481 - accuracy: 0.9805 - val_loss: 0.6163 - val_accuracy: 0.9186\n",
      "Epoch 28/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4416 - accuracy: 0.9802 - val_loss: 0.6126 - val_accuracy: 0.9165\n",
      "Epoch 29/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4361 - accuracy: 0.9808 - val_loss: 0.6093 - val_accuracy: 0.9186\n",
      "Epoch 30/30\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.4337 - accuracy: 0.9830 - val_loss: 0.6063 - val_accuracy: 0.9172\n",
      "Đã train xong Fold  9\n",
      "* Chi tiết các fold\n",
      "> Fold 1 - Loss: 0.6578392386436462 - Accuracy: 91.25538468360901%\n",
      "> Fold 2 - Loss: 0.6569302082061768 - Accuracy: 91.42100214958191%\n",
      "> Fold 3 - Loss: 0.6577313542366028 - Accuracy: 91.27194285392761%\n",
      "> Fold 4 - Loss: 0.6555479168891907 - Accuracy: 91.32162928581238%\n",
      "> Fold 5 - Loss: 0.6577907204627991 - Accuracy: 91.34647250175476%\n",
      "> Fold 6 - Loss: 0.6569204330444336 - Accuracy: 91.42100214958191%\n",
      "> Fold 7 - Loss: 0.658800482749939 - Accuracy: 91.14773273468018%\n",
      "> Fold 8 - Loss: 0.6573523879051208 - Accuracy: 91.19741916656494%\n",
      "> Fold 9 - Loss: 0.6590748429298401 - Accuracy: 91.26366376876831%\n",
      "> Fold 10 - Loss: 0.6580005288124084 - Accuracy: 91.31335020065308%\n",
      "* Đánh giá tổng thể các folds:\n",
      "> Accuracy: 91.29595994949341 (Độ lệch +- 0.0835055487295496)\n",
      "> Loss: 0.6575988113880158\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "             Am nhac       0.92      0.93      0.93       813\n",
      "             Am thuc       0.99      0.93      0.96       400\n",
      "        Bat dong san       0.99      0.95      0.97       282\n",
      "             Bong da       0.99      1.00      0.99      1464\n",
      "         Chung khoan       0.99      0.96      0.97       320\n",
      "              Cum ga       0.99      0.98      0.98       381\n",
      "    Cuoc song do day       0.65      0.90      0.75       405\n",
      "              Du hoc       0.98      0.91      0.94       394\n",
      "             Du lich       0.91      0.97      0.94       565\n",
      "       Duong vao WTO       0.99      0.81      0.89       191\n",
      "            Gia dinh       0.88      0.59      0.70       280\n",
      "    Giai tri tin hoc       0.79      0.93      0.85       707\n",
      "            Giao duc       0.91      0.93      0.92       707\n",
      "           Gioi tinh       0.88      0.92      0.90       268\n",
      "    Hackers va Virus       1.00      0.87      0.93       319\n",
      "             Hinh su       0.99      0.90      0.95       196\n",
      "     Khong gian song       0.96      0.93      0.95        58\n",
      "  Kinh doanh quoc te       0.89      0.93      0.91       559\n",
      "             Lam dep       0.94      0.96      0.95       735\n",
      "            Loi song       0.73      0.63      0.67       214\n",
      "             Mua sam       0.78      0.68      0.73        84\n",
      "            My thuat       0.99      0.81      0.89       144\n",
      "   San khau dien anh       0.94      0.93      0.93      1030\n",
      "San pham tin hoc moi       0.91      0.85      0.88       595\n",
      "              Tennis       1.00      0.98      0.99       283\n",
      "        The gioi tre       0.83      0.82      0.83       380\n",
      "          Thoi trang       0.86      0.88      0.87       302\n",
      "\n",
      "            accuracy                           0.91     12076\n",
      "           macro avg       0.91      0.88      0.90     12076\n",
      "        weighted avg       0.92      0.91      0.91     12076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle = True)\n",
    "data = {}\n",
    "i = 0\n",
    "loss_list = []\n",
    "accuracy_list = []\n",
    "model_list = {}\n",
    "for train_index, val_index in skf.split(X_train, y_train):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", val_index)\n",
    "    data['X_train' + str(i)], data['X_val' + str(i)]= X_train[train_index], X_train[val_index]\n",
    "    data['y_train' + str(i)], data['y_val' + str(i)] = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "    model = get_model()\n",
    "    # Train model\n",
    "    model.fit(data['X_train' + str(i)], data['y_train' + str(i)],\n",
    "              batch_size=32,\n",
    "              epochs=30,\n",
    "              validation_data=(data['X_val' + str(i)], data['y_val' + str(i)]),\n",
    "              verbose=1)\n",
    "    \n",
    "    # Test và in kết quả\n",
    "    scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(\"Đã train xong Fold \", i)\n",
    "\n",
    "    # Thêm thông tin accuracy và loss vào list\n",
    "    accuracy_list.append(scores[1] * 100)\n",
    "    loss_list.append(scores[0])\n",
    "    model_list[\"model\" + str(i)] = model\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "# In kết quả tổng thể\n",
    "print('* Chi tiết các fold')\n",
    "for i in range(0, len(accuracy_list)):\n",
    "    print(f'> Fold {i+1} - Loss: {loss_list[i]} - Accuracy: {accuracy_list[i]}%')\n",
    "\n",
    "print('* Đánh giá tổng thể các folds:')\n",
    "print(f'> Accuracy: {np.mean(accuracy_list)} (Độ lệch +- {np.std(accuracy_list)})')\n",
    "print(f'> Loss: {np.mean(loss_list)}')\n",
    "\n",
    "\n",
    "pred = 0\n",
    "for model in model_list:\n",
    "    pred += model_list[model].predict(X_test)*0.1\n",
    "    \n",
    "label_pred = np.argmax(pred, axis = 1)\n",
    "print(metrics.classification_report(y_test, label_pred, target_names= lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
